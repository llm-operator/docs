Welcome to LLM Operator documentation!
======================================

.. raw:: html

   <p style="text-align:center">
   <a class="github-button" href="https://github.com/llm-operator/llm-operator" data-show-count="true" data-size="large" aria-label="Star llm-operator/llm-operator on GitHub">Star</a>
   <script async defer src="https://buttons.github.io/buttons.js"></script>
   </p>

   <p style="text-align:center">
   <strong>Transform your GPU clusters into a powerhouse for generative AI workloads</strong>
   </p>


Do you want an API compatible with OpenAI to leverage the extensive GenAI ecosystem?
If so, LLM Operator is what you need.
It instantly builds a software stack that provides an OpenAI-compatible API for inference, fine-tuning,
and model management.

Check out the :doc:`getting_started` section for further information, including
how to install LLM Operator.

Pleas also see the presentation below to what you can do with LLM Operator:

.. raw:: html

   <iframe src="https://www.slideshare.net/slideshow/embed_code/key/4h5i9Kg8WQatub?hostedIn=slideshare&page=upload" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"></iframe>


Contents
--------

.. toctree::

   getting_started
   tutorial
   inference
   models
   rag
   fine_tuning
   jupyter_notebook
   training
   gpu_showback
   user_management
   access_control
   architecture
   multi_cluster_deployment
   integrations
   roadmap
