Roadmap
=======

Milestone 0 (Completed)
-----------------------
- [X] OpenAI compatible API
- [X] Models: ``google-gemma-2b-it``

Milestone 1 (Completed)
-----------------------

- [X] API authorization with Dex
- [X] API key management
- [X] Quota management for fine-tuning jobs
- [X] Inference autoscaling with GPU utilization
- [X] Models: ``Mistral-7B-Instruct``, ``Meta-Llama-3-8B-Instruct``, and ``google-gemma-7b-it``

Milestone 2 (In-progress)
-------------------------

- [X] Organization & project management
- [X] MLflow integration
- [ ] Dynamic model loading & offloading in inference
- [ ] Jupyter Notebook workspace creation
- [ ] Events and metrics for fine-tuning jobs
- [ ] More models
- [ ] Object store other than MinIO
- [ ] Installation doc for KEDA and Kueue
- [ ] Monitoring & alerting

Milestone 3
-----------

- [ ] Inference optimization (e.g., vLLM)
- [ ] GPU showback
- [ ] Non-Nvidia GPU support
- [ ] Multi-GPU fine-tuning jobs
- [ ] Frontend
- [ ] Multi k8s cluster deployment
- [ ] VectorDB installation
- [ ] Postgres installation with high availability
