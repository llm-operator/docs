Roadmap
=======

Milestone 0 (Completed)
-----------------------
- [X] OpenAI compatible API
- [X] Models: ``google-gemma-2b-it``

Milestone 1 (Completed)
-----------------------

- [X] API authorization with Dex
- [X] API key management
- [X] Quota management for fine-tuning jobs
- [X] Inference autoscaling with GPU utilization
- [X] Models: ``Mistral-7B-Instruct``, ``Meta-Llama-3-8B-Instruct``, and ``google-gemma-7b-it``

Milestone 2 (Completed)
-----------------------

- [X] Jupyter Notebook workspace creation
- [X] Dynamic model loading & offloading in inference (initial version)
- [X] Organization & project management
- [X] MLflow integration
- [X] Weights & Biases integration for fine-tuning jobs
- [X] VectorDB installation and RAG
- [X] Multi k8s cluster deployment (initial version)

Milestone 3 (In-progress)
-------------------------

- [X] Object store other than MinIO
- [X] Multi-GPU general-purpose training jobs
- [ ] Inference optimization (e.g., vLLM)
- [ ] Frontend
- [ ] GPU showback
- [ ] Models: ``Meta-Llama-3-8B-Instruct``, ``Meta-Llama-3-70B-Instruct``, ``deepseek-coder-6.7b-base``

Milestone 4
-----------

- [ ] Non-Nvidia GPU support
- [ ] Multi-GPU LLM fine-tuning jobs
- [ ] Multi k8s cluster deployment (file and vector store management)
- [ ] Events and metrics for fine-tuning jobs
- [ ] More models
- [ ] Postgres installation with high availability
- [ ] Monitoring & alerting
